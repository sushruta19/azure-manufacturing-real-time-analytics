{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "792894df-f6ee-4f41-8889-20870722e9b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Bronze Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b2626d2-eade-4572-83e1-68b043c39593",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-5060743471615095>, line 10\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# ===========================================================\u001B[39;00m\n",
       "\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# 01_bronze_ingestion_minimal.py\u001B[39;00m\n",
       "\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m#\u001B[39;00m\n",
       "\u001B[0;32m   (...)\u001B[0m\n",
       "\u001B[1;32m      7\u001B[0m \u001B[38;5;66;03m# and stores as managed DLT tables under the Bronze schema.\u001B[39;00m\n",
       "\u001B[1;32m      8\u001B[0m \u001B[38;5;66;03m# ===========================================================\u001B[39;00m\n",
       "\u001B[0;32m---> 10\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mdlt\u001B[39;00m\n",
       "\u001B[1;32m     11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpyspark\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msql\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfunctions\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m current_timestamp, to_date, col\n",
       "\u001B[1;32m     13\u001B[0m STORAGE_ACC \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstoragemanufacture\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\n",
       "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'dlt'"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "ModuleNotFoundError",
        "evalue": "No module named 'dlt'"
       },
       "metadata": {
        "errorSummary": ""
       },
       "removedWidgets": [],
       "sqlProps": {
        "breakingChangeInfo": null,
        "errorClass": "NOTEBOOK_USER_ERROR",
        "pysparkCallSite": null,
        "pysparkFragment": null,
        "pysparkSummary": null,
        "sqlState": "KD00G",
        "stackTrace": null,
        "startIndex": null,
        "stopIndex": null
       },
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
        "File \u001B[0;32m<command-5060743471615095>, line 10\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# ===========================================================\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# 01_bronze_ingestion_minimal.py\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;66;03m# and stores as managed DLT tables under the Bronze schema.\u001B[39;00m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;66;03m# ===========================================================\u001B[39;00m\n\u001B[0;32m---> 10\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mdlt\u001B[39;00m\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpyspark\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msql\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfunctions\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m current_timestamp, to_date, col\n\u001B[1;32m     13\u001B[0m STORAGE_ACC \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstoragemanufacture\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
        "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'dlt'"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ===========================================================\n",
    "# 01_bronze_ingestion_minimal.py\n",
    "#\n",
    "# Bronze Layer - Minimal ingestion of raw PLC data\n",
    "# -----------------------------------------------------------\n",
    "# Simply reads from the landing zone (ADLS Delta files)\n",
    "# and stores as managed DLT tables under the Bronze schema.\n",
    "# ===========================================================\n",
    "\n",
    "import dlt\n",
    "from pyspark.sql.functions import current_timestamp, to_date, col\n",
    "\n",
    "STORAGE_ACC = \"storageadlsmanufacture\"\n",
    "BASE_PATH = f\"abfss://landing@{STORAGE_ACC}.dfs.core.windows.net/factory_streaming\"\n",
    "\n",
    "# ---------------- FEEDER ----------------\n",
    "@dlt.table(name=\"01_bronze.feeder_raw\", comment=\"Raw Feeder PLC stream (no transformations)\")\n",
    "def feeder_raw():\n",
    "    return (\n",
    "        spark.readStream.format(\"delta\")\n",
    "             .load(f\"{BASE_PATH}/feeder\")\n",
    "             .withColumn(\"event_time\", col(\"event_time\").cast(\"timestamp\"))\n",
    "             .withColumn(\"ingest_timestamp\", col(\"ingest_time\").cast(\"timestamp\"))\n",
    "             .withColumn(\"ingest_date\", to_date(\"ingest_timestamp\"))\n",
    "    )\n",
    "\n",
    "# ---------------- DRILL CUTTER ----------------\n",
    "@dlt.table(name=\"01_bronze.drillcutter_raw\", comment=\"Raw DrillCutter PLC stream (no transformations)\")\n",
    "def drillcutter_raw():\n",
    "    return (\n",
    "        spark.readStream.format(\"delta\")\n",
    "             .load(f\"{BASE_PATH}/drillcutter\")\n",
    "             .withColumn(\"event_time\", col(\"event_time\").cast(\"timestamp\"))\n",
    "             .withColumn(\"ingest_timestamp\", col(\"ingest_time\").cast(\"timestamp\"))\n",
    "             .withColumn(\"ingest_date\", to_date(\"ingest_timestamp\"))\n",
    "             .withColumnRenamed(\"temp\", \"temperature_c\")\n",
    "             .withColumnRenamed(\"vibration\", \"vibration_mms\")\n",
    "    )\n",
    "\n",
    "# ---------------- POLISHER ----------------\n",
    "@dlt.table(name=\"01_bronze.polisher_raw\", comment=\"Raw Polisher PLC stream (no transformations)\")\n",
    "def polisher_raw():\n",
    "    return (\n",
    "        spark.readStream.format(\"delta\")\n",
    "             .load(f\"{BASE_PATH}/polisher\")\n",
    "             .withColumn(\"event_time\", col(\"event_time\").cast(\"timestamp\"))\n",
    "             .withColumn(\"ingest_timestamp\", col(\"ingest_time\").cast(\"timestamp\"))\n",
    "             .withColumn(\"ingest_date\", to_date(\"ingest_timestamp\"))\n",
    "             .withColumnRenamed(\"temp\", \"temperature_c\")\n",
    "             .withColumnRenamed(\"vibration\", \"vibration_mms\")\n",
    "    )\n",
    "\n",
    "# ---------------- INSPECTOR ----------------\n",
    "@dlt.table(name=\"01_bronze.inspector_raw\", comment=\"Raw Inspector PLC stream (no transformations)\")\n",
    "def inspector_raw():\n",
    "    return (\n",
    "        spark.readStream.format(\"delta\")\n",
    "             .load(f\"{BASE_PATH}/inspector\")\n",
    "             .withColumn(\"event_time\", col(\"event_time\").cast(\"timestamp\"))\n",
    "             .withColumn(\"ingest_timestamp\", col(\"ingest_time\").cast(\"timestamp\"))\n",
    "             .withColumn(\"ingest_date\", to_date(\"ingest_timestamp\"))\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "01_Bronze_Ingestion",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}